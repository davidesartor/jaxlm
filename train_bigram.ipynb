{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import optax\n",
    "import flax\n",
    "from flax.training.train_state import TrainState\n",
    "\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import TextDataset\n",
    "import models\n",
    "import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = jax.random.key(0)\n",
    "context_len = 8\n",
    "batch_size = 32\n",
    "\n",
    "dataset = TextDataset(data_path=\"shakespeare.txt\")\n",
    "model = models.BigramLM(vocab_size=len(dataset.tokenizer.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f53001433d04cb0a75db1faacb59809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01764b9e80f443c18a4124f9453d1a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086ff45196c847c5b1784de0187c97dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7249ae3ffaaa4eedaf6235f89785b56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187ad044624c4bc595693d450e899240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7e7513f497480ebdc671b8ab3f3e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee07f1adbbe4cb0a82f99c6e41c37d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb0a5bc0cf14b108c28e17bed77976f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71767cbd6a74223b3cc2cc2ae8471eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83649a807f8457aba264a5110f6a3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f8a15d408f4bf397a9341558d0627d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.507021188735962\n",
      "Generation test: \n",
      "\u001b[94m To be or \u001b[0mou ave t\n",
      "WAS:\n",
      "masun,\n",
      "CIO:\n",
      "Pe hom thakice te wosthatth'de blanovecing by:\n",
      "Motinins; nisureilt:\n",
      "NDR:\n",
      "Whe e\n",
      "\n",
      "\n",
      "LO: ng t abld meltoforrear,\n",
      "Welds twhes tine whe, w, in.\n",
      "Wiselal oromes? r, hiak yo? stin:\n",
      "CES:\n",
      "Lur mamarth omyobrd. Bate;\n",
      "\n",
      "SAngall hean,\n",
      "Wh bs thertiaulonke-han heeread IXE:\n",
      "\n",
      "Mad bayin th, ant.\n",
      "\n",
      "Hin sthil;\n",
      "Ses te de s fisorttrrmbr w, thitoro.\n",
      "\n",
      "He myooustintens manth tom y wo' s ham kerispavilinon IRUSo.\n",
      "Thed ELUShy clyove?\n",
      "t pid llleeral in:\n",
      "As?\n",
      "S:\n",
      "II ol veaveay! as tharule Ifordoused prmu"
     ]
    }
   ],
   "source": [
    "optimization_step = jax.jit(partial(training.optimization_step, loss_fn=training.logit_prediction_loss))\n",
    "get_batch = jax.jit(partial(dataset.get_batch, batch_size=batch_size, context_len=context_len))\n",
    "generate_token = jax.jit(partial(model.apply, method=model.generate_token))\n",
    "def generate_text(params, prompt: str, length=500, rng_key=jax.random.key(0)):\n",
    "    context = dataset.tokenizer.encode(prompt)\n",
    "    print(\"\\033[94m\", dataset.tokenizer.decode(context), \"\\033[0m\", end=\"\")\n",
    "    for sub_rng in jax.random.split(rng_key, length):\n",
    "        next_token, context = generate_token(params, context, sub_rng)\n",
    "        print(dataset.tokenizer.decode(next_token[None]), end=\"\")\n",
    "\n",
    "losses = []\n",
    "train_state = TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=model.init(rng_key, dataset.sample(context_len, rng_key)),\n",
    "    tx=optax.adam(3e-4),\n",
    ")\n",
    "for epoch_rng_key in tqdm(jax.random.split(rng_key, 10)):\n",
    "    for batch_rng_key in tqdm(jax.random.split(epoch_rng_key, 10000), leave=False):\n",
    "        x, y = get_batch(rng_key=batch_rng_key)\n",
    "        train_state, loss_value = optimization_step(train_state, x, y)\n",
    "        losses.append(loss_value)\n",
    "print(f\"Loss: {sum(losses) / len(losses)}\\nGeneration test: \")\n",
    "generate_text(train_state.params, prompt=\"To be or\", rng_key=rng_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
